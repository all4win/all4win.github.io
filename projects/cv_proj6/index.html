<html>
<head>
<title>Computer Vision Project 6: Deep Learning</title>
<link href='http://fonts.googleapis.com/css?family=Nunito:300|Crimson+Text|Droid+Sans+Mono' rel='stylesheet' type='text/css'>
<link rel="stylesheet" title="Default" href="styles/github.css">
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>  

<link rel="stylesheet" href="highlighting/styles/default.css">
<script src="highlighting/highlight.pack.js"></script>

<style type="text/css">
body {
	margin: 0px;
	width: 100%;
	font-family: 'Crimson Text', serif;
	font-size: 20px;
	background: #fcfcfc;
}
h1 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 28px;
	margin: 25px 0px 0px 0px;

}

h2 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 32px;
	margin: 15px 0px 35px 0px;
	color: #333;	
	word-spacing: 3px;
}

h3 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 26px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}
h4 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 22px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}

h5 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 18px;
	margin: 10px 0px 10px 0px;
	color: #111;
	word-spacing: 2px;
}

p, li {
	color: #444;
}

a {
	color: #DE3737;
}

.container {
	margin: 0px auto 0px auto;
	width: 1160px;
}

#header {
	background: #333;
	width: 100%;
}

#headersub {
	color: #ccc;
	width: 960px;
	margin: 0px auto 0px auto;
	padding: 20px 0px 20px 0px;
}

.chart {
	width: 480px;
}
.lol {
	font-size: 16px;
	color: #888;
	font-style: italic;
}
.sep {
	height: 1px;
	width: 100%;
	background: #999;
	margin: 20px 0px 20px 0px;
}
.footer{
	font-size: 16px;
}
.latex {
	width: 100%;
}

.latex img {
	display: block;
	margin: 0px auto 0px auto;
}

pre {
	font-family: 'Droid Sans Mono';
	font-size: 14px;
}

table td {
  text-align: center;
  vertical-align: middle;
}

table td img {
  text-align: center;
  vertical-align: middle;
}

#contents a {
}
</style>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>
</head>
<body>
<div id="header" >
<div id="headersub">
<h1>Tiancheng Gong (tgong7)</h1>
</div>
</div>
<div class="container">

<h2> Project 6: Deep Learning</h2>


<p> 	This project aims to learn the classifications of the images by buidling a network. There there several modification I made on the starter code to achieve the goal accuracy.</p>

<div style="clear:both">
<h3>Jitting Data</h3>

<p> 	According to the instructions, I mirror half of the training images so that I can have 50% images for training. </p>
<pre><code>numOfImg =  size(im, 4);
for ii = 1 : numOfImg
    if (rand() < 0.5)
        im(:, :, :, ii) = fliplr(im(:, :, :, ii));
    end
end
</code></pre>

</br>
<div style="clear:both">
<h3>Zero Center</h3>

<p> 	According to the instructions, I subtract the mean of the pixel values from each pixel to achieve the zero center(normalization).</p>
<pre><code>cur_image = imresize(cur_image, image_size);
cur_image = cur_image - mean(mean(cur_image));
</code></pre>

</br>
<div style="clear:both">
<h3>Regularization</h3>

<p> 	According to the instructions, I add a dropout layer for regularization.</p>
<pre><code>net.layers{end+1} = struct('type', 'dropout', 'rate', 0.5) ;
</code></pre>

</br>
<div style="clear:both">
<h3>Deeper Network</h3>

<p> 	By adding more convolutional layers and max-pool layers and adjusting the learning rate and number of Epochs properly, I construct a deeper network. The comparasion between the results of the shallow network and the deeper network is shown below.</p>
<pre><code>% Deeper Network
net.layers{end+1} = struct('type', 'conv', ...
                           'weights', {{f*randn(10,10,1,10, 'single'), zeros(1, 10, 'single')}}, ...
                           'stride', 1, ...
                           'pad', 0, ...
                           'name', 'conv1') ;
                       
net.layers{end+1} = struct('type', 'pool', ...
                           'method', 'max', ...
                           'pool', [5 5], ...
                           'stride', 2, ...
                           'pad', 0) ;

net.layers{end+1} = struct('type', 'relu') ;

net.layers{end+1} = struct('type', 'conv', ...
                           'weights', {{f*randn(5,5,1,10, 'single'), zeros(1, 10, 'single')}}, ...
                           'stride', 1, ...
                           'pad', 0, ...
                           'name', 'conv1') ;
                       
net.layers{end+1} = struct('type', 'pool', ...
                           'method', 'max', ...
                           'pool', [3 3], ...
                           'stride', 2, ...
                           'pad', 0) ;

net.layers{end+1} = struct('type', 'relu') ;

net.layers{end+1} = struct('type', 'conv', ...
                           'weights', {{f*randn(3,3,1,10, 'single'), zeros(1, 10, 'single')}}, ...
                           'stride', 1, ...
                           'pad', 0, ...
                           'name', 'conv1') ;
                       
net.layers{end+1} = struct('type', 'pool', ...
                           'method', 'max', ...
                           'pool', [2 2], ...
                           'stride', 2, ...
                           'pad', 0) ;

net.layers{end+1} = struct('type', 'relu') ;
                       
net.layers{end+1} = struct('type', 'dropout', 'rate', 0.5) ;

net.layers{end+1} = struct('type', 'conv', ...
                           'weights', {{f*randn(4,4,10,15, 'single'), zeros(1, 15, 'single')}}, ...
                           'stride', 1, ...
                           'pad', 0, ...
                           'name', 'fc1') ;
</code></pre>

<h3>Results of the shallow network and the deeper network.</h3>

<table border=1>
<tr>
<td align="center"> Settings and Accuracy </td>
<td align="center"> Filter Visualization</td>
<td align="center"> Learning Curve Plot </td>
</tr>


<tr>
<td>0. Learning Rate: 0.0001; Number of Epoch: 50</br>
1. 1st conv layer with 10 (9*9) filters, stride 1.</br>
2. 1st maxpooling layer with 10 (7*7) filters, stride 7.</br>
3. fc layer with 15 (8*8) filters, stride 1.</br>
<b>Lowest Error Rate: 0.461</b></td>
<td> <img src="results/shallow_filter.jpg" width="100%"/> </td>
<td> <img src="results/shallow.jpg" width="100%"/> </td>
</tr>

<tr>
<td>0. Learning Rate: 0.001; Number of Epoch: 200</br>
1. 1st conv layer with 10 (10*10) filters, stride 1.</br>
2. 1st maxpooling layer with 10 (5*5) filters, stride 2.</br>
3. 2nd conv layer with 10 (5*5) filters, stride 1.</br>
4. 2nd maxpooling layer with 10 (3*3) filters, stride 2.</br>
5. 3rd conv layer with 10 (3*3) filters, stride 1.</br>
6. 3rd maxpooling layer with 10 (2*2) filters, stride 2.</br>
7. fc layer with 15 (4*4) filters, stride 1.</br>
<b>Lowest Error Rate: 0.542</b></td>
<td> <img src="results/deep_filter.jpg" width="100%"/> </td>
<td> <img src="results/deep.jpg" width="100%"/> </td>
</tr>

<tr>
<td>0. Learning Rate: 0.001; Number of Epoch: 200</br>
1. 1st conv layer with 10 (12*12) filters, stride 1.</br>
2. 1st maxpooling layer with 10 (6*6) filters, stride 2.</br>
3. 2nd conv layer with 10 (6*6) filters, stride 1.</br>
4. 2nd maxpooling layer with 10 (3*3) filters, stride 2.</br>
5. 3rd conv layer with 10 (3*3) filters, stride 1.</br>
6. 3rd maxpooling layer with 10 (2*2) filters, stride 2.</br>
7. fc layer with 14 (3*3) filters, stride 1.</br>
<b>Lowest Error Rate: 0.612</b></td>
<td> <img src="results/deep_filter(1).jpg" width="100%"/> </td>
<td> <img src="results/deep(1).jpg" width="100%"/> </td>
</tr>

</table>

<div style="clear:both" >
<p> 	 The learning result of the deeper network is not good as the reulst fo the shallow network. The reason might be that the number of epoch is not big enough for reaching the best learning result, or it might be related to the learning rate since the learning curve becomes flat when as the number of iterations grows. If a dynamic learning rate can be applied on the learning process, the learning curve may converge more quickly and reach the better result.</p>
</div>
</body>
</html>
